HACKING

Want to hack Apilator? Read on!

Apilator consists of three Java packages: 
com.zavedil.apilator.core: the core package, which (normally) needs no modification - unless you want to hack with it!
com.zavedil.apilator.app: the main API application
com.eclipsesource.json: JSON encoding/decoding library, used as s drop-in. 

THE APP
=======

Most of the information you need to build your own API is already in the README file. Here is just brief summary:

The Config.java class is where all configurable parameters reside. They are reasonable defaults, but some (like session storage cache and access log file) will be better off at another, less exposed (read: non-world-readable) location.

The Endpoint,java class is an abstract class which every API endpoint should extend. It provides 4 main methods, each invoked depending on the HTTP method used: .get(), .post(), .put(), .delete(). It also has two methods called by the core package: 
.onLoad() is called when a new task has arrived. It is main purpose is to be part of the Automated Session Management (ASM), i.e. out check whether a session cookie name is configured and if so, whether such cookie was supplied. On the later case the session with the corresponding ID is automatically retrieved and made available to your method. If no session coke was found or if the session has expired a blank session is reared for you. 
.onCompletion() is called after your method completes and is used to retrieve the output object. If ASM is enabled, it also stored back the session into the storage. 
There is also a skeleton helper method called .populateNewSession which is called whenever a new session is created. By default this method does nothing. It is intended for you to put there any session initialisation code you wish. 

The Static.java class is ready-to-use an Endpoint for serving static content. In the Config.java class set the desired document root directory. When this endpoint is invoked, it will take the local part of the URL, strip its own name from it, append the remainder to the document root and will serve the resulting resource. If you want the local part of your  static URLs to begin not with /Static but with something else, either rename this class and/or set up a rewrite URL in your reverse proxy (load balancer). 

The Stats.java is an Endpoint providing run-time statistics for the local server. When this endpoint is invoked, it will retrieve the summary data for the specified interval and serve it as text or JSON. If you want the local part of your  static URLs to begin not with /Static but with something else, either rename this class and/or set up a rewrite URL in your reverse proxy (load balancer).

To create your own endpoint, just copy the EndpointExample.java class and use it as template. You will ask find ready-to-use code samples in it. 

THE CORE
=========

The core package consists of several major parts: 
- TCP server which handles all the inbound TCP connections: these are the classes which names begin with 'ServerTcp'
- HTTP parser which is triggered when new data arrives over TCP: these are the classes which names begin with 'Http'
- Objects for input and output of HTTP data between the TCP server and HTTP Parser: these are the classes which names begin with 'Task'
- Session Manager which takes care of the session storage and its synchronisation between multiple servers: these are the classes which names begin with 'Session' or 'Client' (it also uses an instance of the ServerTcp)
- Queues implementation class (for HTTP and for Session Manager): the Queue class.
- Auxiliary classes for automatic configuration upon start-up (ConfigAuto.java), logging (Logger.java) and statistics gathering (ServerStats.java) 


TCP SERVER FOR HTTP

The TCP server is built using non-blocking I/O with one thread taking care of the socket and multiple threads processing requests. Unlike blocking I/O here one thread is not bound to one client, hence threads utilisation can be much higher and fewer threads (read: system resources) are needed to serve same amount of data. 

The TCP server is run in two instances (i.e. two main server threads) - one for serving HTTP data and one for serving Session Manager (i.e. for sending sessions when asked by another server; uses a separate TCP socket). At start-up, a pre-configured number of worker threads are started (separately for HTTP and Session Manager 

When a new piece of data arrives, the TCP server will put into the respective queue (HTTP or SessionManager), from where it will be picked up by a free worker. If all workers are busy, the request will wait for the first one to become available. Because in TCP there is no way to tell when transmission is complete and because with non-blocking I/O data is always received in chunks, it is up to the worker to decide whether the request is complete and should be processed or whether more data is expected. In the latter case, the worker will simply return and the next arriving chunk over the same channel will be appended to the previous by the main server thread. If the former case the worker will process the data and will write back a response; when sending it to the client, the main server thread will clean up the accumulated chunks in the channel, making it ready for next request. 

The statistics gathering runs at two tiers: 
- After serving a request, each ServerWorkerHttp or ServerWorkerSessionManager worker will write some statistics in ServerStats static hash maps (<Long,Long>): one table for the number of requests served by each worker (incremented per worker after a request is served) and one table for the total execution time (sum per worker). Worker threads use their creation timestamp as unique key. The ServerStatsSchedule class keeps 2 sets of such maps, one for HTTP workers and one for Session Manager workers. 
- A timer launches each minute a TimerTask defined in the ServerStats class, which task goes over the tables form the previous points and sums up their contents, also counting the number of records. It then writes the summary for served requests, busy time and number of workers into three aggregation static hash maps (<Long,Long>) in the ServerStatsSchedule. In these maps the timestamp of the aggregation is the key. When aggregation completes, the ServerStatsTask clears the hash maps used by the workers. It also removes all records that are older than 15 minutes from the aggregation hash maps. The ServerStatsSchedule class keeps 2 sets of aggregation maps, one for HTTP workers and one for Session Manager workers. 

When the Static.java class is invoked to serve statistics, it uses an offset from the current time and fetches all aggregated records within the resulting timeframe. It then calculates several numbers and gives them back as either text (key/value pairs, this is default) or JSON (if format=json is specified in the GET request). By default, the information is returned for the last 5 minutes; you can change this by specifying offset=X where X is the number of minutes (min 1, max 15). By default, the information is returned for the HTTP serving threads; if you are interested in the Session Manager threads, add source=sm to the GET parameters. The following numbers are returned: 
- server_uptime: number of milliseconds since the server was started
- total_requests: number of requests served during the specified interval
- avg_threads: average number of active threads
- avg_exec_time: average execution time per request in milliseconds
- avg_busy_percent: average percent of the time each worker was busy


HTTP PARSER

The HTTP parser first tries to parse HTTP headers and, for POST/PUT requests, if the size of the headers plus the provided Content-Length match the size of the available data, to parse the body. The parser duplicates the input data and creates two readers from the two copies, one text and one binary. The text ones is used for faster parsing of headers and for all sections of the body except those which have Content-Transfer-Encoding set to "binary", "8-bit" or not set at all. The HTTP parser keeps a track for the number of bytes the text readers has yielded and uses this count to read binary data form the binary reader. When binary data is read, first all data from the current position to the end of the input is read and the first occurrence of the boundary is sought. Then the same read is repeated but only to the beginning of the boundary. Next the last occurrence of CRLF inside this fragment is sought and the read from input is once again repeated, this time to the detected CRLF and the extracted is completed. 

The HTTP parser provides two main hash tables, one with headers (<String,String>) and another with GET/POST params (<String,Object>). The latter is because param value may be uploaded data (file etc.); this means that,when working with params, it is your responsibility to cast the object into proper type. The parsers also provides a third hash table (<String, String>) with the cookies (extracted from the corresponding HTTP header). The parser separately provides the local part of the URL (without any GET params).

Once the HTTP parser completes, the ServerWorkerHttp uses the local part of the URL to decide if the request s for static content or should be redirected to the API. For this it checks the local part of the URL against a pre-defined pattern and if the local part begins with this patterns, it is considered a static delivery. In this case the remainder of the local part is mapped to the pre-deficned DocumentRoot and the resulting resource is served. 

If the ServerWorkerHttp decides the call is not for static content, it then retrieves the text between first two slashes from the local part of the URL. It uses this as an API endpoint name to invoke. Invocation is done using reflection, which allows you to create arbitrary endpoint names without need for the core package to know them. From the reflected class worker invokes the method with the same (lowercase) name as the HTTP method and passes ti an TaskInput object with the data from the HTTP parser. 

When the API endpoint is instantiated, the .onLoad() function checks if the ASM is enabled and if so, seeks a cookie with a pre-defined name. If cookie is found, its value is treated as session ID and the corresponding session is sought in the session storage. If the session is found, it is added to the TaskInput object; if not, a blank session is created and attached there. 

All the business logic should be developed inside the endpoint's method.

When the method completes, the ServerWorkerHttp invokes the .onCompletion() method from the reflected class which stored the session back (if ASM is enabled) and returns the TaskOutput object. The data from the TaskOutput object is then used to construct the HTTP reply to the client. 


SESSION MANAGER

The session is a local object that contains a hash map (<String, Object>) as primary storage for key/value pairs as well as some timestamps. You can store whatever objects you want inside the session, but need to separately track their type and cast them back properly upon retrieval. The session provides methods .put(), .get() and .del() to add, fetch and remove key/value pairs. 

The session has three internal timestamps: 
- created: set to the UNIX timestamp in milliseconds of session's creation; available read-only via the .getCreated() method.
- updated:set to the UNIX timestamp in milliseconds of session's last update (i.e. invocation of .put() or .delete()); available read-only through the .getUpdated() method.
- ttl: set to the UNIX timestamp in milliseconds of session's expiration time. If ASM is enabled, when saving the session to storage the expiration time will be re-calculated using a pre-defined TTL constant: if the constant is positive, the expiration will be set to current time plus TTL (thus effectively extending the session's expiration time each time it is used); if it is negative, expiration will be set to session's creation time plus TTL (thus effectively fixing session's life span); if it is zero, expiration will not be touched (and because default is 0, if you have not changed it, the session will likely be destroyed by the Session Manager within a minute). Expiration is available to manually get and set using the .getTtl() and .setTtl(milliseconds) methods. 

The SessionManagerCleanup runs a clean-up task at predefined intervals (by default each minute). The task compares the TTL time in each session in the storage with the current time and remove the expired sessions from the storage. The same process dumps the session storage to a file; when the Session Manager is starting, it checks the file and if present, loads the session storage form it, allowing sessions to survive server restarts. 

When running multiple servers in parallel, they will synchronise their session storages so that no matter where the request goes, its session is always available. Part of the exchange (announcements and availability queries) is made over multicast allowing to run the cluster of servers without any configuration and also allowing on-the-fly addition and removal of servers. The actual session transfer is made over TCP. 

When a new session is created or deleted, the corresponding server will create an instance of SessionMessage, set inside the session's ID and an action flag (AVAIL for added, DELETE for removed), will serilalise and queue it for sending over multicast to a pre-defined group and port. For this, the ClientMulticast isused; it runs in a separate thread and holds a static blocking queue (FIFO). When a message is added to the queue, the ClientMulticast will send it over the network using multicast.

In a separate thread a multicast server ServerMulticast runs, attached to the same multicast group and port. When a request arrives, the ServerMulticast deserialises it and acts depending on the content: 
- if message type is DELETE, it will check whether the local storage has the specified key and if so, the key will be deleted. 
- if message type is AVAIL, it will use the same message, but substitute the IP address with its own, will set the message type to GET and will place it in the ClientTcp's queue. 
- if message type is WHOHAS, it will check if the local storage has the session_id from the message; if yes, it will substitute the IP address with its own, will set the message type to ISAT and will place it in the ClientMulticast's queue.
- if message type is ISAT, it will check whether it needs this sesson (i.e. misisng form local storage or present, but with older updated values) and if yes, it will use the same message, but substitute the IP address with its own, will set the message type to GET and will place it in the ClientTcp's queue. 

The unicast session retrieval requests (messages of type GET) are handled by a ClientTcp running in a separate process which holds a static blocking queue (FIFO). When a message is added to the queue, the ClientTcp will send it over the network using TCP to the IP address, specified in the message and to the pre-configured Session Manager's TCP port.

Session manager runs an instance of the ServerTcp similar to the one used for HTTP, but listening at a different port. It has its own worker type, ServerTcpWorkerSm which receives chunks of incoming data and try to deserialise it into SessionMessage object; if attempt fails, then more data is expected and the worker returns; if they succeed, they extract the action from the deserialised object and act upon it: the worker checks if the the specified key is available in the local storage and, if so, gets the session, serialises it and sends it back with a messag type set to POST. 

The AVAIL -> GET -> POST sequence allows any server in the cluster to receive a new or updated session from another server. 

To allow a newly added server to obtain existing sessions which are misisng from its storage, the .get() method will not immediately return NULL, but will also perform the following actions: 
- Create a new SessionMessage with a type of WHOHAS and place it in the queue of the ClientMulticast; from there it will be picked up and sent to all other servers. The .get() method will then wait for the session to arrive from another server (but no longer than the pre-configured timeout).
- When ServerMulticast receives a WHOHAS message, it will check session ID availability in local storage and if found, will change messages type to ISAT and will send it back using multicast. 
- When ServerMulticast receives a ISAT message, it will check if we still need this session (i.e. missing from lcoal storage or present, but with older value of updated field) and if needed will change messages type to GET and will handle it to the ClientTcp for retrieval.
- When ClientTcp get the GET message from its queue, it will send the message to the server specified in it using TCP.
- When ServerTcp receives the GET message, it will check if session ID availability in local storage and if found will attach it to the same message, change mesage type to POST and send it back the ClientTcp. 
- When ClientTcp receives the POST message, it will check if we still need this session (i.e. missing from lcoal storage or present, but with older value of updated field) and if needed will store it in the local storage.
- When the .get() method awakes from the wait() it will check whether the session ID is now available in the local storage. If it is missing, it will either continue to wait (if the pre-configured timeout has not expired), or will consider the session non-existent and will return NULL (leading to a blank session creation). 

The following diagrams illustrate the three scnearios for storage update: 

Server A							Server B
-----------------------------------------------
// Session deleted
(Multicast client) DELETE	---> 	(Multicast server) deletes session


//  Session created or updated
(Multicast client) AVAIL	---> 	(Multicast server)
												|
(TCP server)				<--- 	(TCP client) GET
|
(TCP server) POST			--->	(TCP client) saves session


//  Session missing in local storage when.get() is called
(Multicast client) WHOHAS	---> 	(Multicast server)
													|
(Multicast server)			<--- 	(Multicast client) ISAT
|
(TCP client) GET			---> 	(TCP server)	
												|
(TCP client) saves session	<--- 	(TCP server) POST


STATIC CONTENT

Static content is served by a separate class StaticContent.java. It takes the same TaskInput object and yields back a TaskOutput object. Note that this class will not serve directory listings; if a request resource is a directory,it will return 404 Not Found instead of 501 Forbidden. 


LOGGING

Logging is provided by a set of static methods in the Logger.java class. The logger has two main functions: 
- Provide logging for each served request in the NCSA Common Log Format; the records are appended to a log file which name and location is configurable. The log will not be rotated by Apilator, it is up to your OS to do so. There records are created automatically by Apilator. 
- Provide logging of system events. Events are classified to 7 standard levels of severity: none, critical, error, warning, notice, trace, debug. The system is configured with one of these level and will only log events which are of same or higher level. Events with severity critical and error will be written to both STDERR and STDOUT while events from all other levels will be written to STDOUT. It is up to your OS to decide where to put the actual output (if you run Apilator from a supervisor like you should, check with its documentation). If you want to add logging to your custom part of the API, use the public methods from Logger class which correspond to the desired level: from Logger.critical() to Logger.debug(). These methods take two arguments, class name and sting to log. See the ExndpoitnExample on how the class name can be automatically obtained.  


AUTOMATIC CONFIGURATION

Upon star-up Apilator will run once the .init() method from ConfigAuto.java class. This method will attempt to auto detect a unicast IP address of a system which will the be used by the ASM. Failure to do so will be considered a critical error and Apilator will abort. 
